{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPlMPF6iwKMk3HsbkIfnz93",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inthyes/ML-Study/blob/main/DeeplearningPytorchTextbook/2_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5njnyafZDsVv",
        "outputId": "e83c9747-7a23-4e86-bbf1-1774a8684545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "tensor([[1, 2],\n",
            "        [3, 4]], device='cuda:0')\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.tensor([[1,2],[3,4]]))\n",
        "print(torch.tensor([[1,2],[3,4]], device = 'cuda:0'))\n",
        "print(torch.tensor([[1,2],[3,4]], dtype = torch.float64))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor([[1, 2,], [3, 4]])\n",
        "print(temp.numpy())\n",
        "\n",
        "# GPU상의 텐서를 CPU의 텐서로 변환한 후 ndarray로 변환\n",
        "temp = torch.tensor([[1, 2,], [3, 4]], device = \"cuda:0\")\n",
        "print(temp.to(\"cpu\").numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNcyxJodKeuw",
        "outputId": "423d18e6-b026-4541-80cb-5b5e0d808845"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n",
            "[[1 2]\n",
            " [3 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.FloatTensor([1, 2, 3, 4, 5, 6, 7])\n",
        "print(temp[0], temp[1], temp[-1])\n",
        "print(\"--------------------------\")\n",
        "print(temp[2:5], temp[4:-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe3O4isnLMNH",
        "outputId": "a61ffce1-41c2-4919-9780-c4d2de949a97"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.) tensor(2.) tensor(7.)\n",
            "--------------------------\n",
            "tensor([3., 4., 5.]) tensor([5., 6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = torch.tensor([1, 2, 3])\n",
        "w = torch.tensor([3, 4, 6])\n",
        "print(w - v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxhr6u6ZLxgk",
        "outputId": "dd136e55-6c91-4cc4-dca3-87d733858793"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor([[1,2],[3,4]])\n",
        "print(temp.shape)\n",
        "print(\"--------------------------\")\n",
        "print(temp.view(4, 1))\n",
        "print(\"--------------------------\")\n",
        "print(temp.view(-1))\n",
        "print(\"--------------------------\")\n",
        "print(temp.view(1, -1))\n",
        "print(\"--------------------------\")\n",
        "print(temp.view(-1, 1))"
      ],
      "metadata": {
        "id": "MNH4a5VhMRM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5fde5c-968f-453f-afe6-96cbd5095734"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n",
            "--------------------------\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n",
            "--------------------------\n",
            "tensor([1, 2, 3, 4])\n",
            "--------------------------\n",
            "tensor([[1, 2, 3, 4]])\n",
            "--------------------------\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/sample_data/mnist_test.csv')"
      ],
      "metadata": {
        "id": "oBWCzkUNdrfh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.from_numpy(data['0'].values).unsqueeze(dim=1).float()\n",
        "y = torch.from_numpy(data['1'].values).unsqueeze(dim=1).float()"
      ],
      "metadata": {
        "id": "QGWlnoS6enA5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, csv_file):\n",
        "    self.label = pd.read_csv(csv_file)\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    sample = torch.tensor(self.label.iloc[idx, 0:3]).int()\n",
        "    label = torch.tensor(self.label.iloc[idx,3]).int()\n",
        "    return sample, label\n",
        "\n",
        "tensor_dataset = CustomDataset('/content/sample_data/mnist_test.csv')\n",
        "dataset = DataLoader(tensor_dataset, batch_Size = 5, shuffle = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "2u-d6YvNfDUX",
        "outputId": "5a64830c-db1e-495c-86af-b1009777f6a1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "DataLoader.__init__() got an unexpected keyword argument 'batch_Size'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-98d62ddaf41f>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtensor_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/sample_data/mnist_test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_Size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: DataLoader.__init__() got an unexpected keyword argument 'batch_Size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "mnist_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (1.0,))\n",
        "])\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "import requests\n",
        "download_root = '../data/MNIST_DATASET'\n",
        "\n",
        "train_dataset = MNIST(download_root, transform = mnist_transform, train = True, download = True)\n",
        "valid_dataset = MNIST(download_root, transform = mnist_transform, train = False, download = True)\n",
        "test_dataset = MNIST(download_root, transform = mnist_transform, train = False, download = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIJPPNi1gImh",
        "outputId": "eb53e8da-e77f-4e8e-ab81-695fb85dc3ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST_DATASET/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 102418617.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST_DATASET/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST_DATASET/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST_DATASET/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 8482297.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST_DATASET/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST_DATASET/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST_DATASET/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 32271857.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST_DATASET/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST_DATASET/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST_DATASET/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 6940083.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST_DATASET/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST_DATASET/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "model = nn.Linear(in_features = 1, out_features = 1, bias = True)"
      ],
      "metadata": {
        "id": "hhUVoaTQiUaZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, inputs):\n",
        "    super(MLP, self).__init__()\n",
        "    self.layer = Linear(inputs, 1)\n",
        "    self.activation = Sigmoid()\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = self.layer(X)\n",
        "    X = self.activation(X)\n",
        "    return X\n"
      ],
      "metadata": {
        "id": "t0W6_6mljHbt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MLP, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 5),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = 64, out_channels = 30, kernel_size = 5),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "\n",
        "    self.layer3 = nn.Sequential(\n",
        "        nn.Linear(in_features = 30 * 5 * 5, out_features = 10, bias = True),\n",
        "        nn.ReLU(inplace = True)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    return x\n",
        "\n",
        "model = MLP()\n",
        "\n",
        "print(\"Printing children\\n-------------------------------\")\n",
        "print(list(model.children()))\n",
        "print(\"\\n\\nPrining Modules\\n-------------------------------\")\n",
        "print(list(model.modules()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QvjqPG7jrj8",
        "outputId": "3fdaec00-ad5d-4dd2-c47b-852d0309fe7a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing children\n",
            "-------------------------------\n",
            "[Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "), Sequential(\n",
            "  (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
            "  (1): ReLU(inplace=True)\n",
            ")]\n",
            "\n",
            "\n",
            "Prining Modules\n",
            "-------------------------------\n",
            "[MLP(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Linear(in_features=750, out_features=10, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "), Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "), Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
            "  (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "), Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
            "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
            "  (1): ReLU(inplace=True)\n",
            "), Linear(in_features=750, out_features=10, bias=True), ReLU(inplace=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MLP(in_features = 1, hidden_features = 20, out_features = -1):\n",
        "  hidden = nn.Linear(in_features = in_features, out_features = hidden_features, bias = True)\n",
        "  activation = nn.ReLU()\n",
        "  output = nn.Linear(in_features = hidden_features, out_features = out_features, bias = True)\n",
        "  net = nn.Sequential(hidden, activation, output)\n",
        "  return net"
      ],
      "metadata": {
        "id": "vDILwYCFmbPv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import optimizer\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr= 0.01, momentum = 0.9)\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer = optimizer, lr_lambda = lambda epoch: 0.95 ** epoch)\n",
        "for epoch in range(1, 100 + 1):\n",
        "  for x, y in dataloader:\n",
        "    optimizer.zero_grad()\n",
        "loss_fn(model(x), y).backward()\n",
        "optimizer.step()\n",
        "scheduler.step()"
      ],
      "metadata": {
        "id": "PE9hSSEEI5q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "  yhat = model(x_train)\n",
        "  loss = criterion(yhat, y_train)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "id": "BFZRU5Q5NYqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJoDkbbqOkda",
        "outputId": "a0d5dc73-76fc-4bd2-8926-207ea1c2ff91"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.1 torchmetrics-1.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchmetrics\n",
        "\n",
        "preds = torch.randn(10, 5).softmax(dim = -1)\n",
        "target = torch.randint(5, (10, ))\n",
        "\n",
        "acc = torchmetrics.functional.accuracy(preds, target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "Mk4a3XxBO0cd",
        "outputId": "ec7320e0-6967-4202-b8a8-ba5fbe164e92"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "accuracy() missing 1 required positional argument: 'task'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-9a06aa2d02a8>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: accuracy() missing 1 required positional argument: 'task'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchmetrics\n",
        "metric = torchmetrics.Accuracy()\n",
        "\n",
        "n_batches = 10\n",
        "for i in range(n_batches):\n",
        "  preds = torch.randn(10, 5).softmax(dim = -1)\n",
        "  target = torch.randint(5, (10, ))\n",
        "\n",
        "  acc = metric(preds, target)\n",
        "  print(f\"Accuracy on batch {i} : {acc}\")\n",
        "acc = metric.compute()\n",
        "print(f\"Accuracy on all data : {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "yX8pS7_0jkSM",
        "outputId": "5da57cbe-8cf8-4b13-b592-3178a52cf002"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Accuracy.__new__() missing 1 required positional argument: 'task'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-07bea70b7516>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Accuracy.__new__() missing 1 required positional argument: 'task'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxvho8nmkYsg",
        "outputId": "82f8ddc9-6734-4349-d4f0-4f4d7bddc38c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.60.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.5.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.25.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter('../chap02/tensorboard')\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  batch_loss = 0.0\n",
        "\n",
        "  for i, (x, y) in enumerate(dataloader):\n",
        "    x, y = x.to(device).float(), y.to(device).float()\n",
        "    outputs = model(x)\n",
        "    loss = criterion(outputs, y)\n",
        "    writer.add_scaler(\"Loss\", loss, epoch)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "6_NBNTLYkiTQ",
        "outputId": "a778c8d3-f2b3-4551-fb11-ceccb8db3d95"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'num_epochs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-725affcacc5c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../chap02/tensorboard'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_epochs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ke1f0arBlJTK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}